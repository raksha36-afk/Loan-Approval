{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90b9bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9882116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('loan_approval_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecedce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Drop the 'loan_id' column as it is not needed for training\n",
    "data.drop('loan_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa897c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in [' education', ' self_employed']:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "221f8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "data[' loan_status'] = LabelEncoder().fit_transform(data[' loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54921f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = data.drop(' loan_status', axis=1)\n",
    "y = data[' loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dca9dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23105535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "464ad456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\91944\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the MLP model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b11c0002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bc17e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.6112 - loss: 0.6604 - val_accuracy: 0.8404 - val_loss: 0.5112\n",
      "Epoch 2/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7210 - loss: 0.5131 - val_accuracy: 0.9180 - val_loss: 0.3113\n",
      "Epoch 3/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8425 - loss: 0.3707 - val_accuracy: 0.9429 - val_loss: 0.2176\n",
      "Epoch 4/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8798 - loss: 0.3271 - val_accuracy: 0.9385 - val_loss: 0.1877\n",
      "Epoch 5/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8849 - loss: 0.2818 - val_accuracy: 0.9473 - val_loss: 0.1717\n",
      "Epoch 6/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9087 - loss: 0.2567 - val_accuracy: 0.9517 - val_loss: 0.1632\n",
      "Epoch 7/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9097 - loss: 0.2501 - val_accuracy: 0.9444 - val_loss: 0.1619\n",
      "Epoch 8/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9179 - loss: 0.2270 - val_accuracy: 0.9473 - val_loss: 0.1581\n",
      "Epoch 9/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2440 - val_accuracy: 0.9502 - val_loss: 0.1541\n",
      "Epoch 10/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9114 - loss: 0.2142 - val_accuracy: 0.9458 - val_loss: 0.1574\n",
      "Epoch 11/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2179 - val_accuracy: 0.9488 - val_loss: 0.1531\n",
      "Epoch 12/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.2342 - val_accuracy: 0.9517 - val_loss: 0.1474\n",
      "Epoch 13/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2236 - val_accuracy: 0.9531 - val_loss: 0.1463\n",
      "Epoch 14/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9261 - loss: 0.1973 - val_accuracy: 0.9502 - val_loss: 0.1468\n",
      "Epoch 15/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9229 - loss: 0.2061 - val_accuracy: 0.9473 - val_loss: 0.1474\n",
      "Epoch 16/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9225 - loss: 0.1834 - val_accuracy: 0.9502 - val_loss: 0.1354\n",
      "Epoch 17/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.1990 - val_accuracy: 0.9531 - val_loss: 0.1384\n",
      "Epoch 18/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.1925 - val_accuracy: 0.9546 - val_loss: 0.1391\n",
      "Epoch 19/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9443 - loss: 0.1639 - val_accuracy: 0.9517 - val_loss: 0.1336\n",
      "Epoch 20/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.1783 - val_accuracy: 0.9546 - val_loss: 0.1331\n",
      "Epoch 21/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.1692 - val_accuracy: 0.9531 - val_loss: 0.1324\n",
      "Epoch 22/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9316 - loss: 0.1708 - val_accuracy: 0.9531 - val_loss: 0.1324\n",
      "Epoch 23/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9353 - loss: 0.1615 - val_accuracy: 0.9517 - val_loss: 0.1310\n",
      "Epoch 24/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.1633 - val_accuracy: 0.9517 - val_loss: 0.1264\n",
      "Epoch 25/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9364 - loss: 0.1780 - val_accuracy: 0.9531 - val_loss: 0.1254\n",
      "Epoch 26/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.1536 - val_accuracy: 0.9531 - val_loss: 0.1243\n",
      "Epoch 27/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9341 - loss: 0.1596 - val_accuracy: 0.9517 - val_loss: 0.1263\n",
      "Epoch 28/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9498 - loss: 0.1719 - val_accuracy: 0.9531 - val_loss: 0.1226\n",
      "Epoch 29/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.1488 - val_accuracy: 0.9575 - val_loss: 0.1208\n",
      "Epoch 30/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.1415 - val_accuracy: 0.9634 - val_loss: 0.1194\n",
      "Epoch 31/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9400 - loss: 0.1497 - val_accuracy: 0.9634 - val_loss: 0.1147\n",
      "Epoch 32/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9408 - loss: 0.1431 - val_accuracy: 0.9590 - val_loss: 0.1153\n",
      "Epoch 33/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9393 - loss: 0.1564 - val_accuracy: 0.9590 - val_loss: 0.1179\n",
      "Epoch 34/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9443 - loss: 0.1428 - val_accuracy: 0.9634 - val_loss: 0.1099\n",
      "Epoch 35/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9455 - loss: 0.1580 - val_accuracy: 0.9634 - val_loss: 0.1086\n",
      "Epoch 36/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.1410 - val_accuracy: 0.9605 - val_loss: 0.1100\n",
      "Epoch 37/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9499 - loss: 0.1391 - val_accuracy: 0.9649 - val_loss: 0.1093\n",
      "Epoch 38/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1352 - val_accuracy: 0.9693 - val_loss: 0.1080\n",
      "Epoch 39/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9420 - loss: 0.1501 - val_accuracy: 0.9634 - val_loss: 0.1069\n",
      "Epoch 40/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9570 - loss: 0.1332 - val_accuracy: 0.9634 - val_loss: 0.1014\n",
      "Epoch 41/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9577 - loss: 0.1186 - val_accuracy: 0.9531 - val_loss: 0.1125\n",
      "Epoch 42/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9543 - loss: 0.1220 - val_accuracy: 0.9531 - val_loss: 0.1050\n",
      "Epoch 43/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9597 - loss: 0.1146 - val_accuracy: 0.9605 - val_loss: 0.1020\n",
      "Epoch 44/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9592 - loss: 0.1155 - val_accuracy: 0.9590 - val_loss: 0.1060\n",
      "Epoch 45/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9604 - loss: 0.1278 - val_accuracy: 0.9561 - val_loss: 0.1053\n",
      "Epoch 46/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9468 - loss: 0.1388 - val_accuracy: 0.9575 - val_loss: 0.0993\n",
      "Epoch 47/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9558 - loss: 0.1295 - val_accuracy: 0.9605 - val_loss: 0.0985\n",
      "Epoch 48/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9538 - loss: 0.1276 - val_accuracy: 0.9605 - val_loss: 0.0986\n",
      "Epoch 49/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1047 - val_accuracy: 0.9678 - val_loss: 0.0936\n",
      "Epoch 50/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9544 - loss: 0.1244 - val_accuracy: 0.9678 - val_loss: 0.0914\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9561 - loss: 0.1332 - val_accuracy: 0.9619 - val_loss: 0.0984\n",
      "Epoch 52/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9589 - loss: 0.1167 - val_accuracy: 0.9649 - val_loss: 0.0906\n",
      "Epoch 53/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1266 - val_accuracy: 0.9634 - val_loss: 0.0945\n",
      "Epoch 54/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1114 - val_accuracy: 0.9619 - val_loss: 0.0950\n",
      "Epoch 55/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.1035 - val_accuracy: 0.9634 - val_loss: 0.0913\n",
      "Epoch 56/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9638 - loss: 0.1146 - val_accuracy: 0.9649 - val_loss: 0.0893\n",
      "Epoch 57/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.1008 - val_accuracy: 0.9634 - val_loss: 0.0858\n",
      "Epoch 58/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9649 - loss: 0.1047 - val_accuracy: 0.9634 - val_loss: 0.0972\n",
      "Epoch 59/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9675 - loss: 0.0923 - val_accuracy: 0.9605 - val_loss: 0.0972\n",
      "Epoch 60/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9672 - loss: 0.1014 - val_accuracy: 0.9678 - val_loss: 0.0956\n",
      "Epoch 61/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.1171 - val_accuracy: 0.9649 - val_loss: 0.0917\n",
      "Epoch 62/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9606 - loss: 0.1094 - val_accuracy: 0.9605 - val_loss: 0.0914\n",
      "Epoch 63/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.0956 - val_accuracy: 0.9634 - val_loss: 0.0881\n",
      "Epoch 64/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.1165 - val_accuracy: 0.9619 - val_loss: 0.0945\n",
      "Epoch 65/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9693 - loss: 0.0960 - val_accuracy: 0.9678 - val_loss: 0.0843\n",
      "Epoch 66/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9666 - loss: 0.0989 - val_accuracy: 0.9649 - val_loss: 0.0935\n",
      "Epoch 67/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9718 - loss: 0.0923 - val_accuracy: 0.9649 - val_loss: 0.0893\n",
      "Epoch 68/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9696 - loss: 0.0928 - val_accuracy: 0.9634 - val_loss: 0.0952\n",
      "Epoch 69/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0969 - val_accuracy: 0.9693 - val_loss: 0.0857\n",
      "Epoch 70/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9614 - loss: 0.0937 - val_accuracy: 0.9678 - val_loss: 0.0951\n",
      "Epoch 71/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9630 - loss: 0.1037 - val_accuracy: 0.9722 - val_loss: 0.0875\n",
      "Epoch 72/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.1017 - val_accuracy: 0.9663 - val_loss: 0.0941\n",
      "Epoch 73/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0743 - val_accuracy: 0.9663 - val_loss: 0.0879\n",
      "Epoch 74/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9702 - loss: 0.0950 - val_accuracy: 0.9707 - val_loss: 0.0991\n",
      "Epoch 75/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9736 - loss: 0.0867 - val_accuracy: 0.9663 - val_loss: 0.0910\n",
      "Epoch 76/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9636 - loss: 0.0954 - val_accuracy: 0.9663 - val_loss: 0.0922\n",
      "Epoch 77/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9665 - loss: 0.0956 - val_accuracy: 0.9663 - val_loss: 0.0906\n",
      "Epoch 78/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9661 - loss: 0.0871 - val_accuracy: 0.9678 - val_loss: 0.0832\n",
      "Epoch 79/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 0.0842 - val_accuracy: 0.9693 - val_loss: 0.0820\n",
      "Epoch 80/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9685 - loss: 0.0990 - val_accuracy: 0.9678 - val_loss: 0.0879\n",
      "Epoch 81/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9658 - loss: 0.0903 - val_accuracy: 0.9707 - val_loss: 0.0884\n",
      "Epoch 82/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9676 - loss: 0.0933 - val_accuracy: 0.9707 - val_loss: 0.0885\n",
      "Epoch 83/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0879 - val_accuracy: 0.9678 - val_loss: 0.0963\n",
      "Epoch 84/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9796 - loss: 0.0655 - val_accuracy: 0.9693 - val_loss: 0.0893\n",
      "Epoch 85/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9718 - loss: 0.0845 - val_accuracy: 0.9707 - val_loss: 0.0916\n",
      "Epoch 86/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9663 - loss: 0.0949 - val_accuracy: 0.9663 - val_loss: 0.0996\n",
      "Epoch 87/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.0872 - val_accuracy: 0.9736 - val_loss: 0.0947\n",
      "Epoch 88/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9755 - loss: 0.0823 - val_accuracy: 0.9678 - val_loss: 0.0938\n",
      "Epoch 89/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0882 - val_accuracy: 0.9693 - val_loss: 0.0927\n",
      "Epoch 90/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9710 - loss: 0.0778 - val_accuracy: 0.9693 - val_loss: 0.0991\n",
      "Epoch 91/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9765 - loss: 0.0780 - val_accuracy: 0.9707 - val_loss: 0.0970\n",
      "Epoch 92/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.0904 - val_accuracy: 0.9649 - val_loss: 0.0936\n",
      "Epoch 93/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.0907 - val_accuracy: 0.9649 - val_loss: 0.0941\n",
      "Epoch 94/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9707 - loss: 0.0856 - val_accuracy: 0.9693 - val_loss: 0.1048\n",
      "Epoch 95/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.0875 - val_accuracy: 0.9693 - val_loss: 0.1017\n",
      "Epoch 96/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9747 - loss: 0.0804 - val_accuracy: 0.9678 - val_loss: 0.0888\n",
      "Epoch 97/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9680 - loss: 0.0944 - val_accuracy: 0.9693 - val_loss: 0.0897\n",
      "Epoch 98/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 0.0868 - val_accuracy: 0.9663 - val_loss: 0.1030\n",
      "Epoch 99/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9706 - loss: 0.0869 - val_accuracy: 0.9649 - val_loss: 0.0966\n",
      "Epoch 100/100\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9709 - loss: 0.0884 - val_accuracy: 0.9707 - val_loss: 0.0967\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b4eb21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9632 - loss: 0.0778\n",
      "Test Accuracy: 96.49%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baebf273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predicting the results\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54c59763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[526  10]\n",
      " [ 20 298]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       536\n",
      "           1       0.97      0.94      0.95       318\n",
      "\n",
      "    accuracy                           0.96       854\n",
      "   macro avg       0.97      0.96      0.96       854\n",
      "weighted avg       0.96      0.96      0.96       854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1eb7bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as mlp_loan_approval_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('mlp.h5')\n",
    "print(\"Model saved as mlp_loan_approval_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11300670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Users\\91944\\anaconda3\\python.exe\n",
      "3.11.3 | packaged by Anaconda, Inc. | (main, Apr 19 2023, 23:46:34) [MSC v.1916 64 bit (AMD64)]\n",
      "Package                      Version\n",
      "---------------------------- -----------\n",
      "absl-py                      1.4.0\n",
      "altair                       5.0.1\n",
      "anyio                        3.7.1\n",
      "argon2-cffi                  21.3.0\n",
      "argon2-cffi-bindings         21.2.0\n",
      "arrow                        1.2.3\n",
      "asgiref                      3.6.0\n",
      "asttokens                    2.2.1\n",
      "astunparse                   1.6.3\n",
      "async-lru                    2.0.3\n",
      "attrs                        23.1.0\n",
      "Babel                        2.12.1\n",
      "backcall                     0.2.0\n",
      "beautifulsoup4               4.12.2\n",
      "bleach                       6.0.0\n",
      "blinker                      1.6.2\n",
      "brotlipy                     0.7.0\n",
      "cachetools                   5.3.1\n",
      "certifi                      2023.5.7\n",
      "cffi                         1.15.1\n",
      "chardet                      4.0.0\n",
      "charset-normalizer           3.1.0\n",
      "click                        8.1.3\n",
      "colorama                     0.4.6\n",
      "comm                         0.1.3\n",
      "conda-package-handling       2.2.0\n",
      "conda_package_streaming      0.9.0\n",
      "contourpy                    1.2.1\n",
      "cryptography                 41.0.3\n",
      "cycler                       0.12.1\n",
      "debugpy                      1.6.7\n",
      "decorator                    5.1.1\n",
      "defusedxml                   0.7.1\n",
      "diffusers                    0.12.0\n",
      "Django                       4.2.1\n",
      "emoji                        2.7.0\n",
      "executing                    1.2.0\n",
      "fastjsonschema               2.17.1\n",
      "ffmpeg-python                0.2.0\n",
      "filelock                     3.12.2\n",
      "Flask                        2.3.2\n",
      "Flask-Cors                   4.0.0\n",
      "Flask-Login                  0.6.2\n",
      "Flask-SQLAlchemy             3.0.3\n",
      "flatbuffers                  23.5.26\n",
      "flit_core                    3.9.0\n",
      "fonttools                    4.53.0\n",
      "fqdn                         1.5.1\n",
      "fsspec                       2023.6.0\n",
      "future                       0.18.3\n",
      "gast                         0.4.0\n",
      "gitdb                        4.0.10\n",
      "GitPython                    3.1.32\n",
      "google-auth                  2.22.0\n",
      "google-auth-oauthlib         1.0.0\n",
      "google-pasta                 0.2.0\n",
      "greenlet                     2.0.2\n",
      "grpcio                       1.57.0\n",
      "h5py                         3.9.0\n",
      "huggingface-hub              0.16.4\n",
      "ide50                        1.0.5\n",
      "idna                         2.10\n",
      "imageio                      2.34.1\n",
      "importlib-metadata           6.0.0\n",
      "imutils                      0.5.4\n",
      "inflect                      6.0.4\n",
      "iniconfig                    2.0.0\n",
      "ipykernel                    6.24.0\n",
      "ipython                      8.14.0\n",
      "ipython-genutils             0.2.0\n",
      "ipywidgets                   8.0.7\n",
      "isoduration                  20.11.0\n",
      "itsdangerous                 2.1.2\n",
      "jedi                         0.18.2\n",
      "Jinja2                       3.1.2\n",
      "joblib                       1.4.2\n",
      "json5                        0.9.14\n",
      "jsonpointer                  2.4\n",
      "jsonschema                   4.18.4\n",
      "jsonschema-specifications    2023.6.1\n",
      "jupyter                      1.0.0\n",
      "jupyter_client               8.3.0\n",
      "jupyter-console              6.6.3\n",
      "jupyter_core                 5.3.1\n",
      "jupyter-events               0.6.3\n",
      "jupyter-lsp                  2.2.0\n",
      "jupyter-server               1.24.0\n",
      "jupyter_server_terminals     0.4.4\n",
      "jupyterlab                   4.0.3\n",
      "jupyterlab-pygments          0.2.2\n",
      "jupyterlab_server            2.23.0\n",
      "jupyterlab-widgets           3.0.8\n",
      "keras                        2.13.1\n",
      "kiwisolver                   1.4.5\n",
      "lazy_loader                  0.4\n",
      "libclang                     16.0.6\n",
      "lime                         0.2.0.1\n",
      "Markdown                     3.4.4\n",
      "markdown-it-py               3.0.0\n",
      "MarkupSafe                   2.1.2\n",
      "matplotlib                   3.9.0\n",
      "matplotlib-inline            0.1.6\n",
      "mdurl                        0.1.2\n",
      "mistune                      3.0.1\n",
      "more-itertools               9.0.0\n",
      "mpmath                       1.3.0\n",
      "mysql-connector-python       8.0.33\n",
      "nbclassic                    1.0.0\n",
      "nbclient                     0.8.0\n",
      "nbconvert                    7.7.1\n",
      "nbformat                     5.9.1\n",
      "nest-asyncio                 1.5.6\n",
      "networkx                     3.3\n",
      "notebook                     6.5.4\n",
      "notebook_shim                0.2.3\n",
      "numpy                        1.26.4\n",
      "oauthlib                     3.2.2\n",
      "opencv-python                4.8.0.76\n",
      "opt-einsum                   3.3.0\n",
      "overrides                    7.3.1\n",
      "packaging                    24.1\n",
      "pandas                       2.2.2\n",
      "pandocfilters                1.5.0\n",
      "parso                        0.8.3\n",
      "pickleshare                  0.7.5\n",
      "pillow                       10.3.0\n",
      "pip                          23.3.1\n",
      "platformdirs                 3.9.1\n",
      "pluggy                       1.5.0\n",
      "prometheus-client            0.17.1\n",
      "prompt-toolkit               3.0.39\n",
      "protobuf                     3.20.3\n",
      "psutil                       5.9.5\n",
      "pure-eval                    0.2.2\n",
      "pyarrow                      12.0.1\n",
      "pyasn1                       0.5.0\n",
      "pyasn1-modules               0.3.0\n",
      "pycparser                    2.21\n",
      "pydantic                     1.10.7\n",
      "pydeck                       0.8.0\n",
      "pydub                        0.25.1\n",
      "Pygments                     2.15.1\n",
      "Pympler                      1.0.1\n",
      "pyOpenSSL                    23.2.0\n",
      "pyparsing                    3.1.2\n",
      "PySocks                      1.7.1\n",
      "pytest                       8.2.2\n",
      "pytest-flask                 1.3.0\n",
      "python-dateutil              2.9.0.post0\n",
      "python-json-logger           2.0.7\n",
      "pytz                         2023.3\n",
      "pytz-deprecation-shim        0.1.0.post0\n",
      "pywin32                      306\n",
      "pywinpty                     2.0.11\n",
      "PyYAML                       6.0.1\n",
      "pyzmq                        25.1.0\n",
      "qtconsole                    5.4.3\n",
      "QtPy                         2.3.1\n",
      "referencing                  0.29.3\n",
      "regex                        2022.10.31\n",
      "requests                     2.25.1\n",
      "requests-oauthlib            1.3.1\n",
      "rfc3339-validator            0.1.4\n",
      "rfc3986-validator            0.1.1\n",
      "rich                         13.5.2\n",
      "rpds-py                      0.8.12\n",
      "rsa                          4.9\n",
      "ruamel.yaml                  0.17.32\n",
      "ruamel.yaml.clib             0.2.7\n",
      "safetensors                  0.3.2\n",
      "scikit-image                 0.24.0\n",
      "scikit-learn                 1.5.0\n",
      "scipy                        1.13.1\n",
      "seaborn                      0.12.2\n",
      "selenium                     3.141.0\n",
      "Send2Trash                   1.8.2\n",
      "six                          1.16.0\n",
      "smmap                        5.0.0\n",
      "sniffio                      1.3.0\n",
      "soupsieve                    2.4.1\n",
      "SQLAlchemy                   2.0.13\n",
      "sqlparse                     0.4.4\n",
      "stack-data                   0.6.2\n",
      "streamlit                    1.25.0\n",
      "sympy                        1.12\n",
      "tenacity                     8.2.2\n",
      "tensorboard                  2.13.0\n",
      "tensorboard-data-server      0.7.1\n",
      "tensorflow                   2.13.0\n",
      "tensorflow-estimator         2.13.0\n",
      "tensorflow-intel             2.13.0\n",
      "tensorflow-io-gcs-filesystem 0.31.0\n",
      "termcolor                    2.3.0\n",
      "terminado                    0.17.1\n",
      "threadpoolctl                3.5.0\n",
      "tifffile                     2024.6.18\n",
      "tinycss2                     1.2.1\n",
      "tokenizers                   0.13.2\n",
      "toml                         0.10.2\n",
      "toolz                        0.12.0\n",
      "torch                        2.0.1\n",
      "tornado                      6.3.2\n",
      "tqdm                         4.66.4\n",
      "traitlets                    5.9.0\n",
      "transformers                 4.26.0\n",
      "typing_extensions            4.5.0\n",
      "tzdata                       2023.3\n",
      "tzlocal                      4.3.1\n",
      "uri-template                 1.3.0\n",
      "uritools                     4.0.1\n",
      "urlextract                   1.8.0\n",
      "urllib3                      1.26.16\n",
      "validators                   0.21.2\n",
      "watchdog                     3.0.0\n",
      "wcwidth                      0.2.6\n",
      "webcolors                    1.13\n",
      "webencodings                 0.5.1\n",
      "websocket-client             1.6.1\n",
      "Werkzeug                     2.3.3\n",
      "wheel                        0.41.1\n",
      "widgetsnbextension           4.0.8\n",
      "win-inet-pton                1.1.0\n",
      "wincertstore                 0.2\n",
      "wordcloud                    1.9.2\n",
      "wrapt                        1.15.0\n",
      "xgboost                      2.1.0\n",
      "zipp                         3.11.0\n",
      "zstandard                    0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\91944\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip list\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Importing the module for LimeTabularExplainer\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lime_tabular\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Instantiating the explainer object by passing in the training set,\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# and the extracted features\u001b[39;00m\n\u001b[0;32m     11\u001b[0m explainer_lime \u001b[38;5;241m=\u001b[39m lime_tabular\u001b[38;5;241m.\u001b[39mLimeTabularExplainer(X_train,\n\u001b[0;32m     12\u001b[0m                                                    feature_names\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m     13\u001b[0m                                                    verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m     14\u001b[0m                                                    mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lime'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "!pip list\n",
    "\n",
    "# Importing the module for LimeTabularExplainer\n",
    "from lime import lime_tabular\n",
    " \n",
    "# Instantiating the explainer object by passing in the training set,\n",
    "# and the extracted features\n",
    "explainer_lime = lime_tabular.LimeTabularExplainer(X_train,\n",
    "                                                   feature_names=features,\n",
    "                                                   verbose=True, \n",
    "                                                   mode='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe67e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index corresponding to the test vector\n",
    "i = 10\n",
    "\n",
    "# Number denoting the top features\n",
    "k = 5\n",
    "\n",
    "# Calling the explain_instance method by passing in the:\n",
    "# 1) ith test vector\n",
    "# 2) prediction function used by our prediction model('reg' in this case)\n",
    "# 3) the top features which we want to see, denoted by k\n",
    "\n",
    "exp_lime = explainer_lime.explain_instance(\n",
    "\tX_test[i], reg.predict, num_features=k)\n",
    "\n",
    "# Finally visualizing the explanations\n",
    "exp_lime.show_in_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64b3c0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\91944\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[0;32m     42\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../model/mlp_loan_approval_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Initialize the SHAP Deep Explainer\u001b[39;00m\n\u001b[0;32m     47\u001b[0m explainer_shap \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mDeepExplainer(model, X_train[:\u001b[38;5;241m100\u001b[39m])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the data\n",
    "# Assuming your data is in a CSV file, replace 'your_dataset.csv' with your actual file name\n",
    "data = pd.read_csv('../model/loan_approval_dataset.csv')\n",
    "\n",
    "# Preprocessing\n",
    "# Drop the 'loan_id' column as it is not needed for training\n",
    "data.drop('loan_id', axis=1, inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in [' education', ' self_employed']:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    data[column] = label_encoders[column].fit_transform(data[column])\n",
    "\n",
    "# Encode the target variable\n",
    "data[' loan_status'] = LabelEncoder().fit_transform(data[' loan_status'])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(' loan_status', axis=1)\n",
    "y = data[' loan_status']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Load the model\n",
    "model = load_model('../model/mlp_loan_approval_model.h5')\n",
    "\n",
    "import shap\n",
    "\n",
    "# Initialize the SHAP Deep Explainer\n",
    "explainer_shap = shap.DeepExplainer(model, X_train[:100])\n",
    "\n",
    "# Index corresponding to the test vector for local explanation\n",
    "i = 10\n",
    "\n",
    "# Compute SHAP values for the ith instance in X_test\n",
    "shap_values = explainer_shap.shap_values(X_test[i:i+1])\n",
    "print(shap_values)\n",
    "\n",
    "# Visualize local explanation\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer_shap.expected_value, shap_values, X_test[i])\n",
    "\n",
    "# Summarize global explanations using SHAP summary plot\n",
    "shap_values_summary = explainer_shap.shap_values(X_test)\n",
    "print(shap_values_summary)\n",
    "shap.summary_plot(shap_values_summary, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916efd39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfdb041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963236c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e41bc17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
